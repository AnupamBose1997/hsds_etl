{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard library\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from highstreets.data import make_dataset as mhsd\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpyro\n",
    "from numpyro.infer import MCMC, NUTS, Predictive, init_to_feasible\n",
    "import numpyro.distributions as dist\n",
    "from jax import random\n",
    "\n",
    "# import jax.numpy as jnp\n",
    "import arviz as az\n",
    "\n",
    "import dill\n",
    "\n",
    "assert numpyro.__version__.startswith(\"0.9.2\")\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "YOY_FILE = os.environ.get(\"YOY_FILE\")\n",
    "PROFILE_FILE = os.environ.get(\"PROFILE_FILE\")\n",
    "PROJECT_ROOT = os.environ.get(\"PROJECT_ROOT\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "sns.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load mastercard spend data along with high street profiles and setup data arrays and time vectors for convenience\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsp = pd.read_excel(PROFILE_FILE)\n",
    "hsd_yoy = pd.read_csv(YOY_FILE, parse_dates=[\"week_start\"])\n",
    "\n",
    "# some important dates\n",
    "nb_dates = pd.to_datetime(\n",
    "    [\n",
    "        \"2020-03-24\",  # first lockdown starts\n",
    "        \"2020-06-15\",  # shops reopen\n",
    "        \"2020-11-05\",  # second lockdown starts\n",
    "        \"2020-12-02\",  # back to 'tier 2' (i.e. partial reopening)\n",
    "        \"2021-01-05\",  # third lockdown starts\n",
    "        \"2021-04-12\",  # shops reopen\n",
    "    ]\n",
    ")\n",
    "\n",
    "# average weekday and weekend expenditure (should probably relax this\n",
    "# later - no need to lose information)\n",
    "# hsd_yoy_minimal = mhsd.get_minimal_df(hsd_yoy, \"yoy_\").dropna(how=\"any\", axis=\"rows\")\n",
    "# hsd_yoy_minimal = mhsd.avg_retail_wd_we(hsd_yoy, \"yoy_\").dropna(how=\"any\", axis=\"rows\")\n",
    "\n",
    "hsd_yoy_minimal = mhsd.stack_retail_we_wd(hsd_yoy, \"yoy_\").dropna(\n",
    "    how=\"any\", axis=\"rows\"\n",
    ")\n",
    "\n",
    "dates_2020 = (\"2020-04-15\", \"2020-10-31\")\n",
    "dates_2020_full = (\"2020-01-01\", \"2020-12-31\")\n",
    "dates_2021 = (\"2021-02-12\", \"2021-08-31\")\n",
    "dates_full = (\"2020-01-01\", \"2021-12-31\")\n",
    "\n",
    "data_2020 = mhsd.extract_data_array(hsd_yoy_minimal, dates_2020, \"txn_amt\")\n",
    "data_2021 = mhsd.extract_data_array(hsd_yoy_minimal, dates_2021, \"txn_amt\")\n",
    "data_2020_full = mhsd.extract_data_array(hsd_yoy_minimal, dates_2020_full, \"txn_amt\")\n",
    "data_full = mhsd.extract_data_array(hsd_yoy_minimal, dates_full, \"txn_amt\")\n",
    "\n",
    "start_times = {\"2020\": \"2020-04-01\", \"2021\": \"2021-04-12\", \"full\": \"2020-04-01\"}\n",
    "tvecs = {\"2020\": data_2020.index, \"2021\": data_2021.index, \"full\": data_full.index}\n",
    "arrays = {\n",
    "    \"2020\": np.transpose(data_2020.to_numpy()),\n",
    "    \"2021\": np.transpose(data_2021.to_numpy()),\n",
    "    \"full\": np.transpose(data_full.to_numpy()),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up data to be used in hierarcical regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = [\n",
    "    \"percentage of commercial addresses (%)\",\n",
    "    \"total estimated number of home workers\",\n",
    "    \"Sum_y2019_07wd\",\n",
    "]\n",
    "full_data = (\n",
    "    hsd_yoy_minimal.join(\n",
    "        hsp[[\"highstreet_id\"] + predictors],\n",
    "        on=\"highstreet_id\",\n",
    "        how=\"left\",\n",
    "        lsuffix=\"_left\",\n",
    "        rsuffix=\"_right\",\n",
    "    )\n",
    "    .drop([\"highstreet_id_right\", \"txn_cnt\"], axis=1)\n",
    "    .rename(columns={\"highstreet_id_left\": \"highstreet_id\"})\n",
    ")\n",
    "full_data[\"weeks_since_start\"] = (\n",
    "    full_data.index - pd.to_datetime(nb_dates[0])\n",
    ") / pd.Timedelta(1, \"W\")\n",
    "train = full_data.loc[nb_dates[0] : nb_dates[1]]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define hierarchical regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(highstreet_id, weeks, hs_obs=None):\n",
    "    mu_a = numpyro.sample(\"mu_a\", dist.Normal(0.0, 1.0))\n",
    "    sigma_a = numpyro.sample(\"sigma_a\", dist.HalfNormal(1.0))\n",
    "    mu_b = numpyro.sample(\"mu_b\", dist.Normal(0.0, 1.0))\n",
    "    sigma_b = numpyro.sample(\"sigma_b\", dist.HalfNormal(1.0))\n",
    "\n",
    "    unique_hs_ids = np.unique(highstreet_id)\n",
    "    n_hs = len(unique_hs_ids)\n",
    "\n",
    "    with numpyro.plate(\"plate_i\", n_hs):\n",
    "        a = numpyro.sample(\"a\", dist.Normal(mu_a, sigma_a))\n",
    "        b = numpyro.sample(\"b\", dist.Normal(mu_b, sigma_b))\n",
    "\n",
    "    sigma = numpyro.sample(\"sigma\", dist.HalfNormal(1.0))\n",
    "    hs_est = a[highstreet_id] + b[highstreet_id] * weeks\n",
    "\n",
    "    with numpyro.plate(\"data\", len(highstreet_id)):\n",
    "        numpyro.sample(\"obs\", dist.Normal(hs_est, sigma), obs=hs_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_obs = train[\"txn_amt\"].values\n",
    "weeks = train[\"weeks_since_start\"].values\n",
    "highstreet_id = train[\"highstreet_id\"].values\n",
    "\n",
    "graph = numpyro.render_model(\n",
    "    model, model_args=(highstreet_id, weeks), render_distributions=True\n",
    ").unflatten()\n",
    "\n",
    "graph.render(\n",
    "    filename=PROJECT_ROOT\n",
    "    + \"/reports/figures/hierarchical_model_graphs/simple_regression_2020_pooled\"\n",
    ")\n",
    "\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model(highstreet_id, weeks, predictors, hs_obs=None):\n",
    "#     mu_gamma_a = numpyro.sample(\n",
    "#         \"mu_gamma_a\",\n",
    "#         dist.MultivariateNormal(\n",
    "#             loc=0.0,\n",
    "#             covariance_matrix=jnp.eye(predictors.shape[0]),\n",
    "#         ),\n",
    "#     )\n",
    "#     sigma_a = numpyro.sample(\"sigma_a\", dist.HalfNormal(1.0))\n",
    "#     mu_gamma_b = numpyro.sample(\"mu_gamma_b\", dist.MultivariateNormal(0.0))\n",
    "#     sigma_b = numpyro.sample(\"sigma_b\", dist.HalfNormal(1.0))\n",
    "\n",
    "#     unique_hs_ids = np.unique(highstreet_id)\n",
    "#     n_hs = len(unique_hs_ids)\n",
    "\n",
    "#     with numpyro.plate(\"plate_i\", n_hs):\n",
    "#         gamma_a = numpyro.sample(\n",
    "#             \"gamma_a\",\n",
    "#             dist.MultivariateNormal(\n",
    "#                 loc=mu_gamma_a,\n",
    "#                 covariance_matrix=sigma_a * jnp.eye(),\n",
    "#             ),\n",
    "#         )\n",
    "#         b = numpyro.sample(\"b\", dist.Normal(mu_b, sigma_b))\n",
    "\n",
    "#     sigma = numpyro.sample(\"sigma\", dist.HalfNormal(1.0))\n",
    "#     hs_est = a[highstreet_id] + b[highstreet_id] * weeks\n",
    "\n",
    "#     with numpyro.plate(\"data\", len(highstreet_id)):\n",
    "#         numpyro.sample(\"obs\", dist.Normal(hs_est, sigma), obs=hs_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample from the posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts_kernel = NUTS(model, init_strategy=init_to_feasible())\n",
    "\n",
    "mcmc = MCMC(nuts_kernel, num_samples=2000, num_warmup=1000)\n",
    "rng_key = random.PRNGKey(0)\n",
    "mcmc.run(rng_key, highstreet_id, weeks, hs_obs=hs_obs)\n",
    "posterior_samples = mcmc.get_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill_file = PROJECT_ROOT + \"/models/bayesian/posterior_samples_basic.pkl\"\n",
    "with open(dill_file, \"wb\") as f:\n",
    "    dill.dump(\n",
    "        posterior_samples,\n",
    "        f,\n",
    "    )\n",
    "\n",
    "\n",
    "dill_file = PROJECT_ROOT + \"/models/bayesian/mcmc_basic.pkl\"\n",
    "with open(dill_file, \"wb\") as f:\n",
    "    dill.dump(\n",
    "        mcmc,\n",
    "        f,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load previous samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill_file = PROJECT_ROOT + \"models/bayesian/posterior_samples_basic.pkl\"\n",
    "with open(dill_file, \"rb\") as f:\n",
    "    posterior_samples = dill.load(f)\n",
    "\n",
    "dill_file = PROJECT_ROOT + \"models/bayesian/mcmc_basic.pkl\"\n",
    "with open(dill_file, \"rb\") as f:\n",
    "    mcmc = dill.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trace plot for centered model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = az.from_numpyro(mcmc)\n",
    "az.plot_trace(data, compact=True, figsize=(14, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare predictions to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weeks_pred = train[train[\"highstreet_id\"] == 1][\"weeks_since_start\"]\n",
    "pred_template = []\n",
    "for i in np.unique(train[\"highstreet_id\"]):\n",
    "    df = pd.DataFrame(columns=[\"highstreet_id\", \"weeks\"])\n",
    "    df[\"weeks\"] = weeks_pred\n",
    "    df[\"highstreet_id\"] = i\n",
    "    pred_template.append(df)\n",
    "pred_template = pd.concat(pred_template, ignore_index=True)\n",
    "\n",
    "highstreet_id = pred_template[\"highstreet_id\"].values\n",
    "weeks = pred_template[\"weeks\"].values\n",
    "predictive = Predictive(model, posterior_samples, return_sites=[\"sigma\", \"obs\"])\n",
    "samples_predictive = predictive(random.PRNGKey(0), highstreet_id, weeks, None)\n",
    "\n",
    "\n",
    "df_act_pred = pd.DataFrame(\n",
    "    columns=[\"highstreet_id\", \"weeks_since_start\", \"txn_amt_pred\", \"sigma\"]\n",
    ")\n",
    "df_act_pred[\"highstreet_id\"] = pred_template[\"highstreet_id\"]\n",
    "df_act_pred[\"weeks_since_start\"] = pred_template[\"weeks\"]\n",
    "df_act_pred[\"txn_amt_pred\"] = samples_predictive[\"obs\"].T.mean(axis=1)\n",
    "df_act_pred[\"sigma\"] = samples_predictive[\"obs\"].T.std(axis=1)\n",
    "df_act_pred[\"hs_inf\"] = df_act_pred[\"txn_amt_pred\"] - df_act_pred[\"sigma\"]\n",
    "df_act_pred[\"hs_sup\"] = df_act_pred[\"txn_amt_pred\"] + df_act_pred[\"sigma\"]\n",
    "df_act_pred = pd.merge(\n",
    "    df_act_pred,\n",
    "    train[[\"highstreet_id\", \"weeks_since_start\", \"txn_amt\"]],\n",
    "    how=\"left\",\n",
    "    on=[\"highstreet_id\", \"weeks_since_start\"],\n",
    ")\n",
    "df_act_pred = df_act_pred.rename(columns={\"txn_amt\": \"txn_amt_true\"})\n",
    "df_act_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chart_highstreet_with_predictions(highstreet_id, ax):\n",
    "    data = df_act_pred[df_act_pred[\"highstreet_id\"] == highstreet_id]\n",
    "    x = data[\"weeks_since_start\"]\n",
    "    ax.set_title(highstreet_id)\n",
    "    ax.plot(x, data[\"txn_amt_true\"], \"o\")\n",
    "    ax.plot(x, data[\"txn_amt_pred\"])\n",
    "    ax = sns.regplot(\n",
    "        x=x, y=data[\"txn_amt_true\"], ax=ax, ci=None, line_kws={\"color\": \"red\"}\n",
    "    )\n",
    "    ax.fill_between(x, data[\"hs_inf\"], data[\"hs_sup\"], alpha=0.5, color=\"#ffcd3c\")\n",
    "    ax.set_ylabel(\"MRLI\")\n",
    "\n",
    "\n",
    "f, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "hs_plot = [189, 310, 446]\n",
    "for i, id in enumerate(hs_plot):\n",
    "    chart_highstreet_with_predictions(id, axes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_w_regressors(highstreet_id, weeks, hs_obs=None):\n",
    "    mu_a = numpyro.sample(\"mu_a\", dist.Normal(0.0, 1.0))\n",
    "    sigma_a = numpyro.sample(\"sigma_a\", dist.HalfNormal(1.0))\n",
    "    mu_b = numpyro.sample(\"mu_b\", dist.Normal(0.0, 1.0))\n",
    "    sigma_b = numpyro.sample(\"sigma_b\", dist.HalfNormal(1.0))\n",
    "\n",
    "    unique_hs_ids = np.unique(highstreet_id)\n",
    "    n_hs = len(unique_hs_ids)\n",
    "\n",
    "    with numpyro.plate(\"plate_i\", n_hs):\n",
    "        a = numpyro.sample(\"a\", dist.Normal(mu_a, sigma_a))\n",
    "        b = numpyro.sample(\"b\", dist.Normal(mu_b, sigma_b))\n",
    "\n",
    "    sigma = numpyro.sample(\"sigma\", dist.HalfNormal(1.0))\n",
    "    hs_est = a[highstreet_id] + b[highstreet_id] * weeks\n",
    "\n",
    "    with numpyro.plate(\"data\", len(highstreet_id)):\n",
    "        numpyro.sample(\"obs\", dist.Normal(hs_est, sigma), obs=hs_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1261e040ca787f5ae3dfea195be8b65b79c591c00963204095cd345a6e2efeeb"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('highstreets')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
