{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard library\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from highstreets.data import make_dataset as mhsd\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "import numpyro\n",
    "from numpyro.infer import MCMC, NUTS, Predictive, init_to_feasible\n",
    "from numpyro.infer.reparam import TransformReparam\n",
    "import numpyro.distributions as dist\n",
    "from jax import random\n",
    "import arviz as az\n",
    "\n",
    "import dill\n",
    "\n",
    "assert numpyro.__version__.startswith(\"0.9.2\")\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "YOY_FILE = os.environ.get(\"YOY_FILE\")\n",
    "PROFILE_FILE = os.environ.get(\"PROFILE_FILE\")\n",
    "PROJECT_ROOT = os.environ.get(\"PROJECT_ROOT\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "sns.set_context(\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load mastercard spend data along with high street profiles and setup data arrays and time vectors for convenience\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsp = pd.read_excel(PROFILE_FILE)\n",
    "hsd_yoy = pd.read_csv(YOY_FILE, parse_dates=[\"week_start\"])\n",
    "\n",
    "# some important dates\n",
    "nb_dates = pd.to_datetime(\n",
    "    [\n",
    "        \"2020-03-24\",  # first lockdown starts\n",
    "        \"2020-06-15\",  # shops reopen\n",
    "        \"2020-11-05\",  # second lockdown starts\n",
    "        \"2020-12-02\",  # back to 'tier 2' (i.e. partial reopening)\n",
    "        \"2021-01-05\",  # third lockdown starts\n",
    "        \"2021-04-12\",  # shops reopen\n",
    "    ]\n",
    ")\n",
    "\n",
    "# average weekday and weekend expenditure (should probably relax this\n",
    "# later - no need to lose information)\n",
    "hsd_yoy_minimal = mhsd.avg_retail_wd_we(hsd_yoy, \"yoy_\").dropna(how=\"any\", axis=\"rows\")\n",
    "\n",
    "dates_2020 = (\"2020-04-15\", \"2020-10-31\")\n",
    "dates_2020_full = (\"2020-01-01\", \"2020-12-31\")\n",
    "dates_2021 = (\"2021-02-12\", \"2021-08-31\")\n",
    "dates_full = (\"2020-01-01\", \"2021-12-31\")\n",
    "\n",
    "data_2020 = mhsd.extract_data_array(hsd_yoy_minimal, dates_2020, \"txn_amt\")\n",
    "data_2021 = mhsd.extract_data_array(hsd_yoy_minimal, dates_2021, \"txn_amt\")\n",
    "data_2020_full = mhsd.extract_data_array(hsd_yoy_minimal, dates_2020_full, \"txn_amt\")\n",
    "data_full = mhsd.extract_data_array(hsd_yoy_minimal, dates_full, \"txn_amt\")\n",
    "\n",
    "start_times = {\"2020\": \"2020-04-01\", \"2021\": \"2021-04-12\", \"full\": \"2020-04-01\"}\n",
    "tvecs = {\"2020\": data_2020.index, \"2021\": data_2021.index, \"full\": data_full.index}\n",
    "arrays = {\n",
    "    \"2020\": np.transpose(data_2020.to_numpy()),\n",
    "    \"2021\": np.transpose(data_2021.to_numpy()),\n",
    "    \"full\": np.transpose(data_full.to_numpy()),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up data to be used in hierarcical regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week_start</th>\n",
       "      <th>highstreet_id</th>\n",
       "      <th>highstreet_name</th>\n",
       "      <th>txn_amt</th>\n",
       "      <th>percentage of commercial addresses (%)</th>\n",
       "      <th>total estimated number of home workers</th>\n",
       "      <th>Sum_y2019_07wd</th>\n",
       "      <th>weeks_since_start</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week_start</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-30</th>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>1</td>\n",
       "      <td>Pimlico Road, Belgravia</td>\n",
       "      <td>0.039</td>\n",
       "      <td>10.004793</td>\n",
       "      <td>10374.0</td>\n",
       "      <td>7354.840627</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-30</th>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>2</td>\n",
       "      <td>Queensway, Westbourne Grove, Bayswater</td>\n",
       "      <td>0.198</td>\n",
       "      <td>6.657224</td>\n",
       "      <td>4388.0</td>\n",
       "      <td>1141.060698</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-30</th>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>3</td>\n",
       "      <td>Carshalton Road, Carshalton.</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.311258</td>\n",
       "      <td>3632.0</td>\n",
       "      <td>1410.542551</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-30</th>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>4</td>\n",
       "      <td>Mitcham Road, Croydon.</td>\n",
       "      <td>1.297</td>\n",
       "      <td>8.472856</td>\n",
       "      <td>2879.0</td>\n",
       "      <td>2159.100879</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-30</th>\n",
       "      <td>2020-03-30</td>\n",
       "      <td>5</td>\n",
       "      <td>Bridge Road, Chessington.</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7.789256</td>\n",
       "      <td>3672.0</td>\n",
       "      <td>2693.808580</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           week_start  highstreet_id                         highstreet_name  \\\n",
       "week_start                                                                     \n",
       "2020-03-30 2020-03-30              1                 Pimlico Road, Belgravia   \n",
       "2020-03-30 2020-03-30              2  Queensway, Westbourne Grove, Bayswater   \n",
       "2020-03-30 2020-03-30              3            Carshalton Road, Carshalton.   \n",
       "2020-03-30 2020-03-30              4                  Mitcham Road, Croydon.   \n",
       "2020-03-30 2020-03-30              5               Bridge Road, Chessington.   \n",
       "\n",
       "            txn_amt  percentage of commercial addresses (%)  \\\n",
       "week_start                                                    \n",
       "2020-03-30    0.039                               10.004793   \n",
       "2020-03-30    0.198                                6.657224   \n",
       "2020-03-30    0.000                                3.311258   \n",
       "2020-03-30    1.297                                8.472856   \n",
       "2020-03-30    0.000                                7.789256   \n",
       "\n",
       "            total estimated number of home workers  Sum_y2019_07wd  \\\n",
       "week_start                                                           \n",
       "2020-03-30                                 10374.0     7354.840627   \n",
       "2020-03-30                                  4388.0     1141.060698   \n",
       "2020-03-30                                  3632.0     1410.542551   \n",
       "2020-03-30                                  2879.0     2159.100879   \n",
       "2020-03-30                                  3672.0     2693.808580   \n",
       "\n",
       "            weeks_since_start  \n",
       "week_start                     \n",
       "2020-03-30           0.857143  \n",
       "2020-03-30           0.857143  \n",
       "2020-03-30           0.857143  \n",
       "2020-03-30           0.857143  \n",
       "2020-03-30           0.857143  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors = [\n",
    "    \"percentage of commercial addresses (%)\",\n",
    "    \"total estimated number of home workers\",\n",
    "    \"Sum_y2019_07wd\",\n",
    "]\n",
    "full_data = (\n",
    "    hsd_yoy_minimal.join(\n",
    "        hsp[[\"highstreet_id\"] + predictors],\n",
    "        on=\"highstreet_id\",\n",
    "        how=\"left\",\n",
    "        lsuffix=\"_left\",\n",
    "        rsuffix=\"_right\",\n",
    "    )\n",
    "    .drop([\"highstreet_id_right\", \"txn_cnt\"], axis=1)\n",
    "    .rename(columns={\"highstreet_id_left\": \"highstreet_id\"})\n",
    ")\n",
    "full_data[\"weeks_since_start\"] = (\n",
    "    full_data.index - pd.to_datetime(nb_dates[0])\n",
    ") / pd.Timedelta(1, \"W\")\n",
    "train = full_data.loc[nb_dates[0] : nb_dates[1]]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define hierarchical regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(highstreet_id, weeks, hs_obs=None):\n",
    "    mu_a = numpyro.sample(\"mu_a\", dist.Normal(0.0, 1.0))\n",
    "    sigma_a = numpyro.sample(\"sigma_a\", dist.HalfNormal(1.0))\n",
    "    mu_b = numpyro.sample(\"mu_b\", dist.Normal(0.0, 1.0))\n",
    "    sigma_b = numpyro.sample(\"sigma_b\", dist.HalfNormal(1.0))\n",
    "\n",
    "    unique_hs_ids = np.unique(highstreet_id)\n",
    "    n_hs = len(unique_hs_ids)\n",
    "\n",
    "    with numpyro.plate(\"plate_i\", n_hs):\n",
    "        a = numpyro.sample(\"a\", dist.Normal(mu_a, sigma_a))\n",
    "        b = numpyro.sample(\"b\", dist.Normal(mu_b, sigma_b))\n",
    "\n",
    "    sigma = numpyro.sample(\"sigma\", dist.HalfNormal(1.0))\n",
    "    hs_est = a[highstreet_id] + b[highstreet_id] * weeks\n",
    "\n",
    "    with numpyro.plate(\"data\", len(highstreet_id)):\n",
    "        numpyro.sample(\"obs\", dist.Normal(hs_est, sigma), obs=hs_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define non-centered version of the same model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_noncentered(highstreet_id, weeks, hs_obs=None):\n",
    "    mu_a = numpyro.sample(\"mu_a\", dist.Normal(0.0, 1.0))\n",
    "    sigma_a = numpyro.sample(\"sigma_a\", dist.HalfNormal(1.0))\n",
    "    mu_b = numpyro.sample(\"mu_b\", dist.Normal(0.0, 1.0))\n",
    "    sigma_b = numpyro.sample(\"sigma_b\", dist.HalfNormal(1.0))\n",
    "\n",
    "    unique_hs_ids = np.unique(highstreet_id)\n",
    "    n_hs = len(unique_hs_ids)\n",
    "\n",
    "    with numpyro.plate(\"plate_i\", n_hs):\n",
    "        with numpyro.handlers.reparam(\n",
    "            config={\n",
    "                \"a\": TransformReparam(),\n",
    "                \"b\": TransformReparam(),\n",
    "            }\n",
    "        ):\n",
    "            a = numpyro.sample(\n",
    "                \"a\",\n",
    "                dist.TransformedDistribution(\n",
    "                    dist.Normal(0.0, 1.0),\n",
    "                    dist.transforms.AffineTransform(mu_a, sigma_a),\n",
    "                ),\n",
    "            )\n",
    "            b = numpyro.sample(\n",
    "                \"b\",\n",
    "                dist.TransformedDistribution(\n",
    "                    dist.Normal(0.0, 1.0),\n",
    "                    dist.transforms.AffineTransform(mu_b, sigma_b),\n",
    "                ),\n",
    "            )\n",
    "\n",
    "    sigma = numpyro.sample(\"sigma\", dist.HalfNormal(1.0))\n",
    "    hs_est = a[highstreet_id] + b[highstreet_id] * weeks\n",
    "\n",
    "    with numpyro.plate(\"data\", len(highstreet_id)):\n",
    "        numpyro.sample(\"obs\", dist.Normal(hs_est, sigma), obs=hs_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_obs = train[\"txn_amt\"].values\n",
    "weeks = train[\"weeks_since_start\"].values\n",
    "highstreet_id = train[\"highstreet_id\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample from the posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts_kernel = NUTS(model, init_strategy=init_to_feasible())\n",
    "\n",
    "mcmc = MCMC(nuts_kernel, num_samples=2000, num_warmup=2000)\n",
    "rng_key = random.PRNGKey(0)\n",
    "mcmc.run(rng_key, highstreet_id, weeks, hs_obs=hs_obs)\n",
    "posterior_samples = mcmc.get_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill_file = PROJECT_ROOT + \"/models/bayesian/posterior_samples_basic.pkl\"\n",
    "with open(dill_file, \"wb\") as f:\n",
    "    dill.dump(\n",
    "        posterior_samples,\n",
    "        f,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 4000/4000 [12:12<00:00,  5.46it/s, 1023 steps of size 9.10e-04. acc. prob=0.78]\n"
     ]
    }
   ],
   "source": [
    "nuts_kernel_noncentered = NUTS(model_noncentered, init_strategy=init_to_feasible())\n",
    "\n",
    "mcmc_noncentered = MCMC(nuts_kernel_noncentered, num_samples=2000, num_warmup=2000)\n",
    "rng_key = random.PRNGKey(0)\n",
    "mcmc_noncentered.run(rng_key, highstreet_id, weeks, hs_obs=hs_obs)\n",
    "\n",
    "posterior_samples_noncentered = mcmc_noncentered.get_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill_file = PROJECT_ROOT + \"/models/bayesian/posterior_samples_noncentered_basic.pkl\"\n",
    "with open(dill_file, \"wb\") as f:\n",
    "    dill.dump(\n",
    "        posterior_samples_noncentered,\n",
    "        f,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load previous samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/conor/dev/highstreets/highstreets/notebooks/exploratory/0.4-cd-explore-hierarchical-regression-pyro.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/conor/dev/highstreets/highstreets/notebooks/exploratory/0.4-cd-explore-hierarchical-regression-pyro.ipynb#ch0000017vscode-remote?line=0'>1</a>\u001b[0m dill_file \u001b[39m=\u001b[39m PROJECT_ROOT \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmodels/bayesian/posterior_samples_basic.pkl\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/conor/dev/highstreets/highstreets/notebooks/exploratory/0.4-cd-explore-hierarchical-regression-pyro.ipynb#ch0000017vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(dill_file, \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/conor/dev/highstreets/highstreets/notebooks/exploratory/0.4-cd-explore-hierarchical-regression-pyro.ipynb#ch0000017vscode-remote?line=2'>3</a>\u001b[0m     posterior_samples \u001b[39m=\u001b[39m dill\u001b[39m.\u001b[39;49mload(f)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/highstreets-BhrLwWIM-py3.8/lib/python3.8/site-packages/dill/_dill.py:313\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, ignore, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///home/conor/.cache/pypoetry/virtualenvs/highstreets-BhrLwWIM-py3.8/lib/python3.8/site-packages/dill/_dill.py?line=306'>307</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(file, ignore\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[1;32m    <a href='file:///home/conor/.cache/pypoetry/virtualenvs/highstreets-BhrLwWIM-py3.8/lib/python3.8/site-packages/dill/_dill.py?line=307'>308</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/conor/.cache/pypoetry/virtualenvs/highstreets-BhrLwWIM-py3.8/lib/python3.8/site-packages/dill/_dill.py?line=308'>309</a>\u001b[0m \u001b[39m    Unpickle an object from a file.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/conor/.cache/pypoetry/virtualenvs/highstreets-BhrLwWIM-py3.8/lib/python3.8/site-packages/dill/_dill.py?line=309'>310</a>\u001b[0m \n\u001b[1;32m    <a href='file:///home/conor/.cache/pypoetry/virtualenvs/highstreets-BhrLwWIM-py3.8/lib/python3.8/site-packages/dill/_dill.py?line=310'>311</a>\u001b[0m \u001b[39m    See :func:`loads` for keyword arguments.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/conor/.cache/pypoetry/virtualenvs/highstreets-BhrLwWIM-py3.8/lib/python3.8/site-packages/dill/_dill.py?line=311'>312</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/conor/.cache/pypoetry/virtualenvs/highstreets-BhrLwWIM-py3.8/lib/python3.8/site-packages/dill/_dill.py?line=312'>313</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m Unpickler(file, ignore\u001b[39m=\u001b[39;49mignore, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\u001b[39m.\u001b[39;49mload()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/highstreets-BhrLwWIM-py3.8/lib/python3.8/site-packages/dill/_dill.py:525\u001b[0m, in \u001b[0;36mUnpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/conor/.cache/pypoetry/virtualenvs/highstreets-BhrLwWIM-py3.8/lib/python3.8/site-packages/dill/_dill.py?line=523'>524</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39mself\u001b[39m): \u001b[39m#NOTE: if settings change, need to update attributes\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/conor/.cache/pypoetry/virtualenvs/highstreets-BhrLwWIM-py3.8/lib/python3.8/site-packages/dill/_dill.py?line=524'>525</a>\u001b[0m     obj \u001b[39m=\u001b[39m StockUnpickler\u001b[39m.\u001b[39;49mload(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    <a href='file:///home/conor/.cache/pypoetry/virtualenvs/highstreets-BhrLwWIM-py3.8/lib/python3.8/site-packages/dill/_dill.py?line=525'>526</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(obj)\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m \u001b[39m==\u001b[39m \u001b[39mgetattr\u001b[39m(_main_module, \u001b[39m'\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    <a href='file:///home/conor/.cache/pypoetry/virtualenvs/highstreets-BhrLwWIM-py3.8/lib/python3.8/site-packages/dill/_dill.py?line=526'>527</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ignore:\n\u001b[1;32m    <a href='file:///home/conor/.cache/pypoetry/virtualenvs/highstreets-BhrLwWIM-py3.8/lib/python3.8/site-packages/dill/_dill.py?line=527'>528</a>\u001b[0m             \u001b[39m# point obj class to main\u001b[39;00m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "dill_file = PROJECT_ROOT + \"models/bayesian/posterior_samples_basic.pkl\"\n",
    "with open(dill_file, \"rb\") as f:\n",
    "    posterior_samples = dill.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trace plot for centered model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = az.from_numpyro(mcmc)\n",
    "az.plot_trace(data, compact=True, figsize=(14, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trace plot for unnoncentered model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_noncentered = az.from_numpyro(mcmc_noncentered)\n",
    "az.plot_trace(data_noncentered, compact=True, figsize=(14, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_noncentered.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare predictions to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "weeks_pred = train[train[\"highstreet_id\"] == 1][\"weeks_since_start\"]\n",
    "pred_template = []\n",
    "for i in np.unique(train[\"highstreet_id\"]):\n",
    "    df = pd.DataFrame(columns=[\"highstreet_id\", \"weeks\"])\n",
    "    df[\"weeks\"] = weeks_pred\n",
    "    df[\"highstreet_id\"] = i\n",
    "    pred_template.append(df)\n",
    "pred_template = pd.concat(pred_template, ignore_index=True)\n",
    "\n",
    "highstreet_id = pred_template[\"highstreet_id\"].values\n",
    "weeks = pred_template[\"weeks\"].values\n",
    "predictive = Predictive(model, posterior_samples, return_sites=[\"sigma\", \"obs\"])\n",
    "samples_predictive = predictive(random.PRNGKey(0), highstreet_id, weeks, None)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    columns=[\"highstreet_id\", \"weeks_since_start\", \"txn_amt_pred\", \"sigma\"]\n",
    ")\n",
    "df[\"highstreet_id\"] = pred_template[\"highstreet_id\"]\n",
    "df[\"weeks_since_start\"] = pred_template[\"weeks\"]\n",
    "df[\"txn_amt_pred\"] = samples_predictive[\"obs\"].T.mean(axis=1)\n",
    "df[\"sigma\"] = samples_predictive[\"obs\"].T.std(axis=1)\n",
    "df[\"hs_inf\"] = df[\"txn_amt_pred\"] - df[\"sigma\"]\n",
    "df[\"hs_sup\"] = df[\"txn_amt_pred\"] + df[\"sigma\"]\n",
    "df = pd.merge(\n",
    "    df,\n",
    "    train[[\"highstreet_id\", \"weeks_since_start\", \"txn_amt\"]],\n",
    "    how=\"left\",\n",
    "    on=[\"highstreet_id\", \"weeks_since_start\"],\n",
    ")\n",
    "df = df.rename(columns={\"txn_amt\": \"txn_amt_true\"})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1261e040ca787f5ae3dfea195be8b65b79c591c00963204095cd345a6e2efeeb"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('highstreets')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
